# Practical Work 3 

## Задача 1 — Параллельная сортировка слиянием на CUDA

Блок-схема алгоритма представлена на изображении `phts/1.png`.

Сортировка слиянием реализована в параллельном виде с учетом архитектуры GPU. Исходный массив сначала разбивается на равные блоки фиксированного размера. Каждый такой блок обрабатывается отдельным блоком потоков CUDA, что позволяет сортировать множество частей массива одновременно.

После завершения локальной сортировки выполняется этап слияния. Отсортированные блоки объединяются попарно, формируя более крупные отсортированные участки. На каждом следующем шаге размер объединяемых блоков увеличивается в два раза. Процесс повторяется до тех пор, пока весь массив не будет объединён в один полностью отсортированный массив.

Данный подход хорошо масштабируется на GPU, так как на ранних этапах алгоритма доступно большое количество независимых задач, которые могут выполняться параллельно.

---

## Задача 2 — Параллельная быстрая сортировка на CUDA

Блок-схема алгоритма представлена на изображении `phts/2.png`.

Быстрая сортировка основана на разбиении массива относительно опорного элемента. В параллельной реализации основное внимание уделяется распараллеливанию этапа разделения массива.

Для каждого сегмента массива выбирается опорный элемент. Потоки CUDA параллельно определяют, к какой части массива относится каждый элемент: меньше или больше опорного. Затем элементы перераспределяются таким образом, чтобы сформировать два независимых подмассива.

Так как рекурсивная структура быстрой сортировки плохо подходит для прямой реализации на GPU, управление границами подмассивов осуществляется на CPU. GPU используется для выполнения наиболее вычислительно затратных операций — параллельного разделения массива. Малые подмассивы сортируются отдельно, чтобы избежать избыточных накладных расходов.

---

## Задача 3 — Параллельная пирамидальная сортировка на CUDA

Блок-схема алгоритма представлена на изображении `phts/3.png`.

Пирамидальная сортировка состоит из двух этапов: построения кучи и последовательного извлечения максимального элемента. Возможности параллелизма в этом алгоритме ограничены его структурой.

Этап построения кучи хорошо поддаётся распараллеливанию. Узлы одного уровня бинарной кучи не зависят друг от друга, поэтому их можно обрабатывать параллельно. Куча строится снизу вверх, уровень за уровнем, с использованием множества потоков CUDA.

Этап извлечения максимума по своей природе является почти последовательным, так как каждый шаг зависит от предыдущего состояния кучи. Поэтому он выполняется без значительного параллелизма. Данный алгоритм наглядно демонстрирует, что не все части классических алгоритмов одинаково хорошо масштабируются на GPU.

---

## Задача 4 — Сравнение производительности CPU и GPU

Блок-схема процесса сравнения представлена на изображении `phts/4.png`.

Для анализа производительности реализованы последовательные версии всех алгоритмов на CPU. Сравнение проводится на массивах различного размера, например 10 000, 100 000 и 1 000 000 элементов.

Для каждого размера массива:
- генерируются входные данные;
- выполняется сортировка на CPU и на GPU;
- измеряется время выполнения каждой версии;
- проверяется корректность результата;
- рассчитывается ускорение при использовании GPU.

Результаты показывают, что GPU демонстрирует преимущество на больших массивах, где накладные расходы окупаются за счёт массового параллелизма. На малых размерах массивов CPU часто оказывается быстрее.

---

## Контрольные вопросы

1. **В чем различие между последовательной и параллельной реализациями сортировки слиянием?**  
   В последовательной реализации все этапы сортировки выполняются одним потоком, поочередно обрабатывая подмассивы и выполняя слияние. В параллельной реализации массив разбивается на части, которые сортируются одновременно разными потоками, а операции слияния выполняются параллельно для независимых участков данных.

2. **Как распределение потоков и блоков влияет на производительность на CUDA?**  
   Эффективное распределение потоков и блоков позволяет максимально загрузить вычислительные ресурсы GPU. Неправильный выбор размеров блоков может привести к простоям вычислительных модулей или избыточному потреблению ресурсов, что снижает общую производительность.

3. **Какие сложности возникают при реализации быстрой сортировки на GPU?**  
   Основные сложности связаны с рекурсивной структурой алгоритма, непредсказуемыми размерами подмассивов и неравномерной нагрузкой между потоками. Кроме того, операции разбиения массива требуют аккуратной синхронизации и эффективной работы с памятью.

4. **В каких случаях параллельная реализация сортировки на GPU может быть менее эффективной, чем на CPU?**  
   GPU может быть менее эффективен при работе с небольшими массивами, когда накладные расходы на передачу данных и запуск ядер превышают выигрыш от параллелизма. Также снижение эффективности наблюдается в алгоритмах с большим количеством последовательных операций или при плохом доступе к памяти.

5. **Почему важно правильно выбирать размер блоков и потоков в CUDA?**  
   Размер блоков и количество потоков напрямую влияют на загрузку вычислительных ресурсов GPU. Если потоков слишком мало, часть вычислительных модулей простаивает. Если слишком много — возрастает конкуренция за регистры и разделяемую память, что снижает число одновременно выполняемых блоков. Правильный выбор конфигурации позволяет добиться высокой степени параллелизма и максимальной производительности.

6. **Как использование разделяемой памяти может повлиять на производительность сортировки?**  
   Разделяемая память значительно быстрее глобальной памяти GPU. Использование shared memory позволяет сократить количество обращений к глобальной памяти, уменьшить задержки и ускорить обмен данными между потоками одного блока. В сортировках это особенно важно при локальной обработке подмассивов, где элементы многократно сравниваются и переставляются.

7. **Что означает принцип «разделяй и властвуй» в контексте алгоритмов сортировки?**  
   Принцип «разделяй и властвуй» заключается в разбиении задачи на более мелкие подзадачи, их независимой обработке и последующем объединении результатов. В сортировках это означает разбиение массива на части (например, в merge sort или quick sort), сортировку этих частей и объединение их в итоговый отсортированный массив. Такой подход хорошо подходит для параллельных вычислений, так как подзадачи могут выполняться одновременно.

---
